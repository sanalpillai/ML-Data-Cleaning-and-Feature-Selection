
# ML Data Cleaning and Feature Selection

## Overview
This repository hosts `ML_Data_Cleaning_and_Feature_Selection.ipynb`, an in-depth assignment conducted on Google Colab focusing on the critical aspects of data cleaning and feature selection in machine learning. The notebook encompasses various techniques and methodologies, including:

- Thorough examination and identification of data types, both numeric and categorical.
- Comprehensive analysis of missing values in the dataset and strategies for handling them.
- Exploration of the likely distributions of numeric variables using statistical and graphical methods.
- Utilization of multiple methods to identify the most relevant independent variables for predicting a target variable.
- Detailed investigation of missing data in independent variables and approaches for dealing with such discrepancies.
- Comparison between training and test sets to ensure data consistency and integrity.
- Assessment of the independence of predictor variables to avoid multicollinearity.
- Identification and ranking of the most significant predictor variables in the dataset.
- Validation of the range and distributions of predictor variables to ensure data quality and relevance.
- Investigation of the effects of outlier removal on the performance of the final predictive model.
- Implementation of various data imputation methods and an evaluation of their effectiveness in recovering missing values.

The project aims to provide a comprehensive view of the data preparation process for machine learning, highlighting the importance of meticulous data cleaning and informed feature selection.

## Assignment Questions
The notebook addresses the following key questions:

- Data types (numeric and categorical)
- Presence of missing values
- Distributions of numeric variables
- Important independent variables for predicting a target variable
- Independent variables with missing data
- Comparing data consistency between training and test sets
- Independence of predictor variables
- Most important predictor variables
- Ranges and distributions of predictor variables
- Effects of removing outliers on the predictive model
- Data imputation methods and their efficacy

## Resources
- Reference Notebook: [ML Data Cleaning and Feature Selection Abalone](https://github.com/aiskunks/YouTube/blob/main/A_Crash_Course_in_Statistical_Learning/ML_Data_Cleaning_and_Feature_Selection/ML_Data_Cleaning_and_Feature_Selection_Abalone.ipynb)
- [Imputation Methods for Missing Data (YouTube Video)](https://www.youtube.com/watch?v=fYhr8eF1ubo)
- [Comprehensive EDA Notebook (Kaggle)](https://www.kaggle.com/pmarcelino/comprehensive-data-exploration-with-python)

## Scoring Rubric
Evaluation criteria include:

- Data-Supported Answers
- Google Colab Compatibility
- Selection and Approval of Public Dataset
- Code Originality and Citation
- Code Explanation and Professionalism
- Licensing Clarification
- Comprehensive Answers to Key Questions

## Google Colab Usage
1. Open Google Colab: [Google Colab](https://colab.research.google.com/)
2. Import the notebook from GitHub by using the repository URL.

## Licensing
This project is released under the MIT License. The details are available in the [LICENSE.md](LICENSE.md) file.
